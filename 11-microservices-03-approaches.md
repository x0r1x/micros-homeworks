# Домашнее задание к занятию «Микросервисы: подходы»

Вы работаете в крупной компании, которая строит систему на основе микросервисной архитектуры.
Вам как DevOps-специалисту необходимо выдвинуть предложение по организации инфраструктуры для разработки и эксплуатации.


## Задача 1: Обеспечить разработку

Предложите решение для обеспечения процесса разработки: хранение исходного кода, непрерывная интеграция и непрерывная поставка. 
Решение может состоять из одного или нескольких программных продуктов и должно описывать способы и принципы их взаимодействия.

Решение должно соответствовать следующим требованиям:
- облачная система;
- система контроля версий Git;
- репозиторий на каждый сервис;
- запуск сборки по событию из системы контроля версий;
- запуск сборки по кнопке с указанием параметров;
- возможность привязать настройки к каждой сборке;
- возможность создания шаблонов для различных конфигураций сборок;
- возможность безопасного хранения секретных данных (пароли, ключи доступа);
- несколько конфигураций для сборки из одного репозитория;
- кастомные шаги при сборке;
- собственные докер-образы для сборки проектов;
- возможность развернуть агентов сборки на собственных серверах;
- возможность параллельного запуска нескольких сборок;
- возможность параллельного запуска тестов.

Обоснуйте свой выбор.

### Решение

1. Облачная платформа:
   - GitLab для хранения исходного кода и системы контроля версий. GitLab поддерживает Git и позволяет создавать приватные репозитории.

2. CI/CD система:
   - GitLab CI/CD интегрирован с GitLab и поддерживает запуск сборок по событиям (например, push, merge request) и по кнопке с указанием параметров.

3. Хранение секретных данных:
   - GitLab позволяет безопасно хранить секретные данные (например, переменные окружения) и использовать их в процессе сборки.

4. Конфигурации и шаблоны:
   - В GitLab можно использовать файл `.gitlab-ci.yml` для настройки сборок и создания шаблонов для различных конфигураций.

5. Докер:
   - Docker для создания собственных образов. Это позволит создавать кастомные шаги при сборке, а также использовать образы для тестирования.

6. Параллельные сборки и тесты:
   - GitLab поддерживает возможность параллельного запуска сборок и тестов. Можно использовать директиву `parallel` в `.gitlab-ci.yml` для этого.

7. Агенты сборки:
   - Если нужно, можно развернуть собственных агентов сборки, используя GitLab Runner, который позволяет запускать сборки на собственных серверах.

Обоснование выбора:
- GitLab — платформа, которая предоставляет все необходимые инструменты для управления проектами и CI/CD в одном месте. Она хорошо интегрируется с Docker и позволяет легко настраивать процессы сборки и тестирования.
- GitLab CI/CD автоматизирует процесс разработки, что повышает скорость и качество разработки.
- GitLab Runner возможность использования собственных агентов сборки даёт гибкость в управлении ресурсами и оптимизации затрат.
- Docker позволяет создать управляемую среду для сборки и тестирования, обеспечивая стабильность и предсказуемость.

## Задача 2: Логи

Предложите решение для обеспечения сбора и анализа логов сервисов в микросервисной архитектуре.
Решение может состоять из одного или нескольких программных продуктов и должно описывать способы и принципы их взаимодействия.

Решение должно соответствовать следующим требованиям:
- сбор логов в центральное хранилище со всех хостов, обслуживающих систему;
- минимальные требования к приложениям, сбор логов из stdout;
- гарантированная доставка логов до центрального хранилища;
- обеспечение поиска и фильтрации по записям логов;
- обеспечение пользовательского интерфейса с возможностью предоставления доступа разработчикам для поиска по записям логов;
- возможность дать ссылку на сохранённый поиск по записям логов.

Обоснуйте свой выбор.

### Решение

1. Fluentd — это мощный инструмент для сбора логов. Он может собирать данные из разных источников, в том числе из stdout, что соответствует твоему требованию о минимальных требованиях к приложениям. Fluentd поддерживает множество плагинов для интеграции с различными системами.

2. Elasticsearch — это распределенная поисковая система, которая отлично подходит для хранения и поиска по логам. Она обеспечит возможность поиска и фильтрации по записям логов, а также гарантированную доставку логов благодаря своей архитектуре.

3. Kibana — это интерфейс для визуализации данных из Elasticsearch. Он обеспечивает удобный пользовательский интерфейс для поиска по записям логов и позволяет разработчикам создавать сохраненные поиски, которые можно делиться с другими пользователями.

Принципы взаимодействия:

- Сбор логов: Приложения пишут логи в stdout. Fluentd на каждом хосте собирает эти логи и передает их в Elasticsearch.
- Хранение: Elasticsearch получает логи от Fluentd и хранит их в индексах, что позволяет быстро производить поиск.
- Анализ и визуализация: Разработчики используют Kibana для доступа к данным в Elasticsearch. Они могут создавать поисковые запросы, фильтры и визуализации, а также сохранять их для дальнейшего использования.

## Задача 3: Мониторинг

Предложите решение для обеспечения сбора и анализа состояния хостов и сервисов в микросервисной архитектуре.
Решение может состоять из одного или нескольких программных продуктов и должно описывать способы и принципы их взаимодействия.

Решение должно соответствовать следующим требованиям:
- сбор метрик со всех хостов, обслуживающих систему;
- сбор метрик состояния ресурсов хостов: CPU, RAM, HDD, Network;
- сбор метрик потребляемых ресурсов для каждого сервиса: CPU, RAM, HDD, Network;
- сбор метрик, специфичных для каждого сервиса;
- пользовательский интерфейс с возможностью делать запросы и агрегировать информацию;
- пользовательский интерфейс с возможностью настраивать различные панели для отслеживания состояния системы.

Обоснуйте свой выбор.

### Решение

1. Prometheus:
   - Сбор метрик: Используется для сбора метрик со всех хостов и сервисов. Prometheus поддерживает экспортеры для сбора системных метрик (node_exporter для CPU, RAM, HDD, Network) и может работать с приложениями через клиентские библиотеки для сбора специфичных метрик.
   - Настройка: Конфигурируй Prometheus для автоматического обнаружения сервисов в Kubernetes с помощью сервисов и аннотаций.

2. Grafana:
   - Пользовательский интерфейс: Используется для визуализации метрик, собранных Prometheus. Grafana позволяет создавать настраиваемые дашборды, где можно агрегировать информацию и отслеживать состояние системы.
   - Панели мониторинга: Создание различных панелей для отображения метрик CPU, RAM, HDD, Network и специфичных метрик для каждого сервиса.

    Сбор метрик:
    - Node Exporter развертывается на всех узлах кластера Kubernetes для сбора системных метрик.
    - Для микросервисов, запущенных в контейнерах Kubernetes, можно настроить Fluentd для автоматического сбора логов из stdout контейнеров.
    - Prometheus настраивается для периодического опроса Node Exporter и других экспортеров, включая пользовательские экспортёры для специфичных метрик.

    Визуализация данных:
    - Grafana подключается к Prometheus как источник данных. Пользователи могут создавать настраиваемые дашборды, добавлять различные графики и панели для визуализации собранных метрик.
    - Настраеваем запросы к Prometheus для отображения необходимых данных.

    Управление оповещениями:
    - В Grafana настраиваем правила оповещения, которые анализируют собранные метрики. В случае достижения определённых пороговых значений, уведомления отправляются через различные каналы (электронная почта, telegram и т.д)

## Задача 4: Логи * (необязательная)

Продолжить работу по задаче API Gateway: сервисы, используемые в задаче, пишут логи в stdout. 

Добавить в систему сервисы для сбора логов Vector + ElasticSearch + Kibana со всех сервисов, обеспечивающих работу API.

### Результат выполнения: 

docker compose файл, запустив который можно перейти по адресу http://localhost:8081, по которому доступна Kibana.
Логин в Kibana должен быть admin, пароль qwerty123456.


## Задача 5: Мониторинг * (необязательная)

Продолжить работу по задаче API Gateway: сервисы, используемые в задаче, предоставляют набор метрик в формате prometheus:

- сервис security по адресу /metrics,
- сервис uploader по адресу /metrics,
- сервис storage (minio) по адресу /minio/v2/metrics/cluster.

Добавить в систему сервисы для сбора метрик (Prometheus и Grafana) со всех сервисов, обеспечивающих работу API.
Построить в Graphana dashboard, показывающий распределение запросов по сервисам.

### Результат выполнения: 

docker compose файл, запустив который можно перейти по адресу http://localhost:8081, по которому доступна Grafana с настроенным Dashboard.
Логин в Grafana должен быть admin, пароль qwerty123456.

---

### Как оформить ДЗ?

Выполненное домашнее задание пришлите ссылкой на .md-файл в вашем репозитории.

---
